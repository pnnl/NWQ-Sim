{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42b08ec",
   "metadata": {},
   "source": [
    "# Demo. Decoder Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "394c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import pymatching\n",
    "import sys\n",
    "sys.path.append(\"../QEC-Codes\")  # Adjust the path to import local modules\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e10c6adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'noise_util' from '/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/NWQ-Sim/stabilizer/src/noise_util.py'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QASM export setup (similar to surface_code_ler)\n",
    "import os, sys, importlib\n",
    "qasm_dir = \"./bb_code_qasm\"\n",
    "os.makedirs(qasm_dir, exist_ok=True)\n",
    "# Make sure we can import the conversion utilities\n",
    "sys.path.insert(0, os.path.abspath(\"../../../src\"))\n",
    "import noise_util as ns\n",
    "importlib.reload(ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f3dcb",
   "metadata": {},
   "source": [
    "This demo introduces the basics of decoders, focusing on pymatching and BP+OSD.  \n",
    "\n",
    "**What does decoder do?**  \n",
    "The input is the error information/syndromes/detection events, along with the detector error model that assigns probability/weights to each error mechanism. For each sample, the decoder will return a vector that gives the predictions for the logical errors that have happened (for surface code it's just one value because there is only one logical operator, for general codes it should a vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c2325",
   "metadata": {},
   "source": [
    "### 1. Pymatching for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c56c1",
   "metadata": {},
   "source": [
    "### Overall Analysis  \n",
    "**LER decreases with increasing code distance and decreasing physical error rate (PER).**  \n",
    "This behavior is consistent with theoretical expectations: as the code distance increases, more physical errors are required to cause a logical error. Similarly, reducing the physical error rate naturally reduces the probability of uncorrectable faults.\n",
    "\n",
    "<!-- (2) **The break-even PER appears to be ≈ 1, meaning the repetition code always outperforms a single bit.**  \n",
    "At first glance, this seems to contradict the classical result that repetition codes only outperform a single bit when \\( p < 0.5 \\) — since majority vote fails above this threshold. However, the classical result is based on **majority vote decoding**, whereas our experiment uses a **matching decoder** (e.g., `pymatching`), which finds the most likely error consistent with the observed syndrome, and can operate effectively even at high error rates. As a result, it can outperform majority vote and maintain logical error suppression for a much wider range of \\( p \\), even approaching 1.\n",
    "\n",
    "(3) **The error threshold appears to be >0.5, meaning that increasing the code distance can suppresses the LER even when the PER is large.**  \n",
    "In standard fault-tolerance theory, a threshold exists below which increasing the code distance improves logical fidelity, and above which larger codes perform worse. Here, because we are using the powerful **matching decoder** on this simple repetition code, the threshold become very large (>0.5). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afeb2e2",
   "metadata": {},
   "source": [
    "### Analysis of LER Scaling\n",
    "\n",
    "In principle, a QEC code of distance $d$ can correct up to $t = \\lfloor \\frac{d-1}{2} \\rfloor$ errors. In the **ideal** case where all these errors are corrected, the leading-order contribution to the LER should be $p^{t+1}$, where $t + 1 = \\lceil \\frac{d+1}{2} \\rceil$ is the weight of uncorrectable errors. In this case, a log-log plot of LER vs $p$ should produce a straight line with slope $t + 1$.\n",
    "\n",
    "In realistic scenarios, however, decoding is imperfect: some correctable errors of weight ≤ $t$ may still lead to logical failure due to decoder suboptimality. As a result, the effective scaling exponent becomes **less than** $t + 1$.\n",
    "\n",
    "Therefore, by fitting the log-log curve $\\log(\\text{LER})$ vs $ \\log(p) $, we can estimate the effective suppression exponent. The **closer the slope is to t+1**, the more effective the decoder is at approaching the ideal case. Conversely, the difference between the slope and the ideal case quantifies suboptimal correction performance under the given noise model and decoding strategy. We can see that when d increases, the leading degrees become closer to t than t+1 and haves the tendency to drop even below t, indicating the fact that it becomes more and more difficult to correct all the errors up to weight t.  \n",
    "\n",
    "The equation $$slope = (d_{eff}+1)/2 $$can give a metric called the \"effective distance $d_{eff}$\", which should be strictly smaller than the true distance $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715586be",
   "metadata": {},
   "source": [
    "Next, we verify the \"exponential suppression\" of LER in code distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff64a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinter\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97560a5d",
   "metadata": {},
   "source": [
    "This time we try to add the 2Q gate error and measurement error as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dba739",
   "metadata": {},
   "source": [
    "(1) We kind of see a \"threshold behavior\": the LER only suppresses as distance increases when PER is below 10.8\\%. See where the d = 7 and d = 9 line intersect.  \n",
    "(2) We also see a \"break even\" behavior: the LER is belowe PER when p < 10\\%, where encoding into repetition code improves the error resilience compared to a bare qubit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c001ba",
   "metadata": {},
   "source": [
    "### 2. Pymatching for Surface Codes  \n",
    "We directly use Sinter to streamline the sampling. This time we include the BPOSD decoder as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5bda64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bposdd import BPOSD\n",
    "import BBcode\n",
    "# from stimbposdd import SinterDecoder_BPOSD, sinter_decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5dbeb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling C++ simulator (MPI)...\n",
      "Compilation successful.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Compile the C++ code once before the loop\n",
    "print(\"Compiling C++ simulator (MPI)...\")\n",
    "# Adjust the path to your C++ file as needed\n",
    "cpp_file_path = './bb_code_sim.cpp'\n",
    "executable_path = './bb_code_sim'\n",
    "\n",
    "compile_command = [\n",
    "    \"mpicxx\",  # Use MPI compiler wrapper\n",
    "    \"-std=c++17\",\n",
    "    \"-O3\",\n",
    "    \"-I../../../../../\", # Include for NWQ-Sim headers\n",
    "    \"-DMPI_ENABLED\",\n",
    "    \"-o\",\n",
    "    executable_path,\n",
    "    cpp_file_path\n",
    "]\n",
    "try:\n",
    "    subprocess.run(compile_command, check=True, capture_output=True, text=True)\n",
    "    print(\"Compilation successful.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Compilation failed.\")\n",
    "    print(\"--- stdout ---\")\n",
    "    print(e.stdout)\n",
    "    print(\"--- stderr ---\")\n",
    "    print(e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17c2d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bb_circuit = \"bicycle_bivariate_144_12_12_memory_Z\"\n",
    "distance = 12 \n",
    "rounds = 12\n",
    "SHOTS = 2000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2cf0fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00995017 0.01980133 0.02955447 0.03921056]\n",
      "[0.00498752 0.00995017 0.01488806 0.01980133]\n",
      "[1.e-06 2.e-06 3.e-06 4.e-06]\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "tasks = []\n",
    "T1 = 10 ** -4\n",
    "T2 = 10 ** -4\n",
    "tau = np.array([1*10**-6, 2*10**-6, 3*10**-6, 4*10**-6])\n",
    "lam = 1/T2 - 1/(2*T1)\n",
    "p_amp = 1 - np.exp(-tau/T1)\n",
    "p_phase = 1 - np.exp(-lam*tau)\n",
    "p_list = (p_amp, p_phase)\n",
    "base_error = 0.01\n",
    "\n",
    "bb_code = BBcode.BBcode(\n",
    "    n=144, k=12, d=12, m=6, l=12,\n",
    "    A=[[3, 0], [0, 1], [0, 2]],\n",
    "    B=[[0, 3], [1, 0], [2, 0]],\n",
    "    shift=[0, 0],\n",
    "    f=[[0, 0], [1, 0], [2, 0], [3, 0], [6, 0], [7, 0], [8, 0], [9, 0], [1, 3], [5, 3], [7, 3], [11, 3]],\n",
    "    g=[[1, 0], [2, 1], [0, 2], [1, 2], [2, 3], [0, 4]],\n",
    "    h=[[0, 0], [0, 1], [1, 1], [0, 2], [0, 3], [1, 3]],\n",
    "    alpha=[[0, 0], [0, 1], [2, 1], [2, 5], [3, 2], [4, 0]],\n",
    "    beta=[[0, 1], [0, 5], [1, 1], [0, 0], [4, 0], [5, 2]],\n",
    ")\n",
    "print(p_amp)\n",
    "print(p_phase)\n",
    "i=0\n",
    "for p_amp, p_phase in zip(p_amp, p_phase):\n",
    "    noise_profile = [0,0,0,0]\n",
    "    bb_circuit = bb_code.build_full_BBcode_circuit(rounds=rounds, noise_profile=noise_profile, observable_type=\"Z\", code_capacity=True)\n",
    "\n",
    "    #Generate stim circuit\n",
    "    model = ns.ErrorModel(bb_circuit)\n",
    "    model.setting_error('Identity', False, f'DEPOLARIZE1({base_error})')\n",
    "    model.setting_error('Single_qubit', False, f'DEPOLARIZE1({base_error})')\n",
    "    model.setting_error('Two_qubit', False, f'DEPOLARIZE2({base_error})')\n",
    "    model.setting_error('Measurement', True, f'PAULI_CHANNEL_1({p_amp/4}, {p_amp/4}, {p_amp/4 + p_phase/2})')\n",
    "    model.setting_error('Reset', True, f'PAULI_CHANNEL_1({p_amp/4}, {p_amp/4}, {p_amp/4 + p_phase/2})')\n",
    "    stim_circuit = model.generate_noisy_circuit()\n",
    "    tasks.append(sinter.Task(circuit=stim_circuit, json_metadata={'d': distance, \"trial\":i}))\n",
    "\n",
    "    #Generate stabsim circuit\n",
    "    model.setting_error('Measurement', True, f'AMPLITUDE_DAMP({p_phase}, {p_amp})')\n",
    "    model.setting_error('Reset', True, f'AMPLITUDE_DAMP({p_phase}, {p_amp})')\n",
    "    stab_circuit = model.generate_noisy_circuit()\n",
    "    qasm_output = ns.stim_to_qasm_with_depolarize_noise(stab_circuit)\n",
    "    # Inject AMPLITUDE_DAMP around M/RESET in QASM using the model settings\n",
    "    qasm_output = ns.inject_amplitude_damp(qasm_output, model)\n",
    "    \n",
    "    try:\n",
    "        qasm_path = os.path.join(qasm_dir, f\"bb_code_d{distance}_p{i}.qasm\")\n",
    "        with open(qasm_path, \"w\") as f:\n",
    "            f.write(qasm_output)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to export QASM for p={p_amp}: {e}\")\n",
    "    i+=1\n",
    "\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72945c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial=0\n",
      "--- Running Stim for task = 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stim LER: 0, Sim+Decoding Time: 37.0962421669974s\n",
      "\n",
      "trial=1\n",
      "--- Running Stim for task = 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n",
      "/Users/garn195/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/ldpc/_legacy_ldpc_v1/_legacy_bposd_decoder.py:45: UserWarning: This is the old syntax for the `bposd_decoder` from `ldpc v1`. Use the `BpOsdDecoder` class from `ldpc v2` for additional features.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stim_lers\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# --- Run Stim-only experiment ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m stim_logical_error_rates = \u001b[43mrun_stim_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSHOTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStim complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStim LERs:\u001b[39m\u001b[33m\"\u001b[39m, stim_logical_error_rates)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mrun_stim_experiment\u001b[39m\u001b[34m(tasks, shots)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Running Stim for task = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m start_time = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m collected_stats = \u001b[43msinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbposd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_decoders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbposd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBPOSD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbp_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mosd_order\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mosd_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mosd_cs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m stim_time = time.perf_counter() - start_time\n\u001b[32m     23\u001b[39m stat = collected_stats[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/sinter/_collection/_collection.py:404\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(num_workers, tasks, existing_data_filepaths, save_resume_filepath, progress_callback, max_shots, max_errors, count_observable_error_combos, count_detection_events, decoders, max_batch_seconds, max_batch_size, start_batch_size, print_progress, hint_num_tasks, custom_decoders, custom_error_count_key, allowed_cpu_affinity_ids)\u001b[39m\n\u001b[32m    402\u001b[39m result = ExistingData()\n\u001b[32m    403\u001b[39m result.data = \u001b[38;5;28mdict\u001b[39m(additional_existing_data.data)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_collect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_batch_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_batch_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount_observable_error_combos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount_observable_error_combos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount_detection_events\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount_detection_events\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhint_num_tasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhint_num_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_existing_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_existing_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_decoders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_decoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_error_count_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_error_count_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallowed_cpu_affinity_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed_cpu_affinity_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_stats\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/sinter/_collection/_collection.py:226\u001b[39m, in \u001b[36miter_collect\u001b[39m\u001b[34m(num_workers, tasks, hint_num_tasks, additional_existing_data, max_shots, max_errors, decoders, max_batch_seconds, max_batch_size, start_batch_size, count_observable_error_combos, count_detection_events, custom_decoders, custom_error_count_key, allowed_cpu_affinity_ids)\u001b[39m\n\u001b[32m    223\u001b[39m manager.start_distributing_work()\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m manager.task_states:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m progress_log:\n\u001b[32m    228\u001b[39m         vals = \u001b[38;5;28mlist\u001b[39m(progress_log)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-PNNL/Project_Repositories/.venv/lib/python3.13/site-packages/sinter/_collection/_collection_manager.py:314\u001b[39m, in \u001b[36mCollectionManager.process_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_message\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshared_worker_output_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m queue.Empty:\n\u001b[32m    316\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:385\u001b[39m, in \u001b[36mSimpleQueue.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rlock:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py:216\u001b[39m, in \u001b[36m_ConnectionBase.recv_bytes\u001b[39m\u001b[34m(self, maxlength)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength < \u001b[32m0\u001b[39m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnegative maxlength\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._bad_message_length()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_stim_experiment(tasks, shots):\n",
    "    stim_lers = []\n",
    "    for i,task in enumerate(tasks):\n",
    "        print(f\"trial={task.json_metadata.get('trial')}\")\n",
    "        print(f\"--- Running Stim for task = {i} ---\")\n",
    "        start_time = time.perf_counter()\n",
    "        collected_stats = sinter.collect(\n",
    "            num_workers=os.cpu_count()//2,\n",
    "            tasks=[task],\n",
    "            decoders=['bposd'],\n",
    "            max_shots=shots,\n",
    "            custom_decoders={\n",
    "                'bposd': BPOSD(\n",
    "                    max_iter=1000,\n",
    "                    bp_method=\"ms\",\n",
    "                    osd_order=10,\n",
    "                    osd_method=\"osd_cs\"\n",
    "                )\n",
    "            },\n",
    "            print_progress=False,\n",
    "        )\n",
    "        stim_time = time.perf_counter() - start_time\n",
    "        stat = collected_stats[0]\n",
    "        stim_ler = stat.errors / stat.shots\n",
    "        if stat.errors == 0: stim_ler = 0\n",
    "        stim_lers.append(stim_ler)\n",
    "        print(f\"Stim LER: {stim_ler}, Sim+Decoding Time: {stim_time:}s\\n\")\n",
    "    return stim_lers\n",
    "\n",
    "# --- Run Stim-only experiment ---\n",
    "stim_logical_error_rates = run_stim_experiment(tasks, SHOTS)\n",
    "print(\"\\nStim complete.\")\n",
    "print(\"Stim LERs:\", stim_logical_error_rates)\n",
    "\n",
    "try:\n",
    "    results_dir = \"./bposd_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    p_amp_arr = 1 - np.exp(-tau / T1)\n",
    "    lam = 1 / T2 - 1 / (2 * T1)\n",
    "    p_phase_arr = 1 - np.exp(-lam * tau)\n",
    "    stim_results_path = os.path.join(results_dir, f\"stim_bposd_results_d{distance}_shots{SHOTS}.txt\")\n",
    "    with open(stim_results_path, \"w\") as f:\n",
    "        f.write(\"# tau\\tp_amp\\tp_phase\\tstim_ler\\n\")\n",
    "        for ta, pa, pp, ler in zip(tau, p_amp_arr, p_phase_arr, stim_logical_error_rates):\n",
    "            f.write(f\"{ta}\\t{pa}\\t{pp}\\t{ler}\\n\")\n",
    "    print(f\"Saved Stim (BP+OSD) results to {stim_results_path}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save Stim results:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ed161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running C++ (MPI) for p = 0 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cpp_lers\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# --- Run C++-only experiment ---\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# reuse SHOTS from previous cell\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m cpp_logical_error_rates = \u001b[43mrun_cpp_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSHOTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mC++ complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mC++ LERs:\u001b[39m\u001b[33m\"\u001b[39m, cpp_logical_error_rates)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mrun_cpp_experiment\u001b[39m\u001b[34m(tasks, shots)\u001b[39m\n\u001b[32m     33\u001b[39m cpp_time = \u001b[32m0\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result.stdout.strip().split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m):\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mTotal C++ simulation time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import bposd_mp\n",
    "\n",
    "def run_cpp_experiment(tasks, shots):\n",
    "    cpp_lers = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        d = task.json_metadata.get('d')\n",
    "        print(f\"\\n--- Running C++ (MPI) for p = {i} ---\")\n",
    "\n",
    "        # Paths\n",
    "        qasm_file_path = os.path.join(qasm_dir, f\"bb_code_d{d}_p{i}.qasm\")\n",
    "        cpp_output_path = os.path.join(qasm_dir, f\"measurements_d{d}_p{i}.txt\")\n",
    "\n",
    "        # MPI execution\n",
    "        num_qubits = task.circuit.num_qubits\n",
    "        mpi_ranks = min(3*os.cpu_count()//4, shots)  # don't spawn more ranks than shots\n",
    "        iters = shots\n",
    "\n",
    "        # env = os.environ.copy()\n",
    "        # env.update({\n",
    "        #     \"OMP_NUM_THREADS\": \"1\",\n",
    "        #     \"OPENBLAS_NUM_THREADS\": \"1\",\n",
    "        #     \"MKL_NUM_THREADS\": \"1\",\n",
    "        #     \"VECLIB_MAXIMUM_THREADS\": \"1\",\n",
    "        #     \"NUMEXPR_NUM_THREADS\": \"1\",\n",
    "        # })\n",
    "\n",
    "        run_command = [\n",
    "            \"mpirun\", \"-np\", str(mpi_ranks),\n",
    "            \"./bb_code_sim\", str(num_qubits), str(iters), qasm_file_path, cpp_output_path\n",
    "        ]\n",
    "\n",
    "        cpp_time = 0\n",
    "        try:\n",
    "            result = subprocess.run(run_command, check=True, capture_output=True, text=True)\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if \"Total C++ simulation time\" in line:\n",
    "                    try:\n",
    "                        cpp_time = float(line.split(':')[1].strip().replace('s', ''))\n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"C++ simulation failed to execute.\")\n",
    "            print(\"Return code:\", e.returncode)\n",
    "            print(\"--- stdout ---\")\n",
    "            print(e.stdout)\n",
    "            print(\"--- stderr ---\")\n",
    "            print(e.stderr)\n",
    "            continue\n",
    "\n",
    "        # Post-process + parallel BPOSD decoding\n",
    "        cpp_ler = 0\n",
    "        try:\n",
    "            with open(cpp_output_path, \"r\") as f:\n",
    "                measurement_strings = [line for line in f.read().strip().split('\\n') if line]\n",
    "\n",
    "            if measurement_strings:\n",
    "                measurement_data = np.array(\n",
    "                    [list(map(int, line.split())) for line in measurement_strings],\n",
    "                    dtype=np.int8\n",
    "                ).astype(bool)\n",
    "\n",
    "                m2d_converter = task.circuit.compile_m2d_converter()\n",
    "                cpp_det_samples, cpp_obs_flips = m2d_converter.convert(\n",
    "                    measurements=measurement_data,\n",
    "                    separate_observables=True\n",
    "                )\n",
    "\n",
    "                dem = task.circuit.detector_error_model(\n",
    "                    decompose_errors=True,\n",
    "                    ignore_decomposition_failures=True\n",
    "                )\n",
    "\n",
    "                from beliefmatching import detector_error_model_to_check_matrices\n",
    "                pcm = detector_error_model_to_check_matrices(dem, allow_undecomposed_hyperedges=True)\n",
    "\n",
    "                logicals_matrix = pcm.observables_matrix\n",
    "                decoder_kwargs = dict(\n",
    "                    max_iter=1000,\n",
    "                    bp_method=\"ms\",\n",
    "                    osd_order=10,\n",
    "                    osd_method=\"osd_cs\",\n",
    "                )\n",
    "\n",
    "                total_shots = len(cpp_det_samples)\n",
    "                if total_shots > 0:\n",
    "                    import math\n",
    "                    num_decode_workers = 3*os.cpu_count()//4\n",
    "\n",
    "                    # Simplified chunking: give each worker a single chunk of tasks\n",
    "                    chunk_size = math.ceil(total_shots / num_decode_workers)\n",
    "                    if chunk_size > 0:\n",
    "                        det_chunks = [cpp_det_samples[i:i + chunk_size] for i in range(0, total_shots, chunk_size)]\n",
    "                        obs_chunks = [cpp_obs_flips[i:i + chunk_size] for i in range(0, total_shots, chunk_size)]\n",
    "                    else:\n",
    "                        det_chunks, obs_chunks = [], []\n",
    "\n",
    "\n",
    "                    # Use a process pool to run decoding in parallel, bypassing the GIL.\n",
    "                    # The worker_init function pre-loads each worker process with the large,\n",
    "                    # shared data (check matrix, priors) to avoid costly serialization.\n",
    "                    with ProcessPoolExecutor(\n",
    "                        max_workers=num_decode_workers,\n",
    "                        initializer=bposd_mp.worker_init,\n",
    "                        initargs=(pcm.check_matrix, pcm.priors, logicals_matrix, decoder_kwargs),\n",
    "                    ) as executor:\n",
    "                        # Map the count_errors function over the chunks of data.\n",
    "                        # The sum of errors from all chunks gives the total.\n",
    "                        total_errors = sum(executor.map(bposd_mp.count_errors, det_chunks, obs_chunks))\n",
    "\n",
    "                    cpp_ler = float(total_errors) / float(total_shots)\n",
    "                else:\n",
    "                    cpp_ler = 0.0\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"C++ output file not found at {cpp_output_path}. Skipping analysis.\")\n",
    "\n",
    "        cpp_lers.append(cpp_ler)\n",
    "        print(f\"C++ LER: {cpp_ler}, Sim Time: {cpp_time}s\")\n",
    "    return cpp_lers\n",
    "\n",
    "# --- Run C++-only experiment ---\n",
    "# reuse SHOTS from previous cell\n",
    "cpp_logical_error_rates = run_cpp_experiment(tasks, SHOTS)\n",
    "print(\"\\nC++ complete.\")\n",
    "print(\"C++ LERs:\", cpp_logical_error_rates)\n",
    "# ...existing code...\n",
    "\n",
    "try:\n",
    "    results_dir = \"./bposd_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    p_amp_arr = 1 - np.exp(-tau / T1)\n",
    "    lam = 1 / T2 - 1 / (2 * T1)\n",
    "    p_phase_arr = 1 - np.exp(-lam * tau)\n",
    "    cpp_results_path = os.path.join(results_dir, f\"cpp_bposd_results_d{distance}_shots{SHOTS}.txt\")\n",
    "    with open(cpp_results_path, \"w\") as f:\n",
    "        f.write(\"# tau\\tp_amp\\tp_phase\\tcpp_ler\\n\")\n",
    "        for ta, pa, pp, ler in zip(tau, p_amp_arr, p_phase_arr, cpp_logical_error_rates):\n",
    "            f.write(f\"{ta}\\t{pa}\\t{pp}\\t{ler}\\n\")\n",
    "    print(f\"Saved C++ (BP+OSD) results to {cpp_results_path}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save C++ results:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55292c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib\n",
    "qasm_dir = \"./bb_code_qasm\"\n",
    "os.makedirs(qasm_dir, exist_ok=True)\n",
    "\n",
    "# New: directory for saved results\n",
    "results_dir = \"./results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Make sure we can import the conversion utilities\n",
    "sys.path.insert(0, os.path.abspath(\"../../../src\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16624232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Results ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(tau/T1, stim_logical_error_rates, 'o-', label='Stim LER (BP+OSD)')\n",
    "plt.plot(tau/T1, cpp_logical_error_rates, 's--', label='C++ LER (BP+OSD)')\n",
    "plt.xlabel(\"Physical Error Rate (p)\")\n",
    "plt.ylabel(\"Logical Error Rate (LER)\")\n",
    "plt.title(f\"LER vs. Physical Error Rate for BB Code (d={distance}) Shots= {SHOTS}\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Reload and plot previously saved results ---\n",
    "\n",
    "# Ensure these parameters match the saved files you want to load\n",
    "# SHOTS = 50000000\n",
    "# distance = 12\n",
    "# T1 = 10**-4\n",
    "# T2 = 10**-4\n",
    "\n",
    "try:\n",
    "    results_dir = \"./results\"\n",
    "    stim_results_path = Path(results_dir) / f\"stim_bposd_results_d{distance}_shots{SHOTS}.txt\"\n",
    "    cpp_results_path = Path(results_dir) / f\"cpp_bposd_results_d{distance}_shots{SHOTS}.txt\"\n",
    "\n",
    "    # Check if files exist\n",
    "    if not stim_results_path.exists() or not cpp_results_path.exists():\n",
    "        missing = []\n",
    "        if not stim_results_path.exists(): missing.append(str(stim_results_path))\n",
    "        if not cpp_results_path.exists(): missing.append(str(cpp_results_path))\n",
    "        raise FileNotFoundError(\"Missing results files: \" + \", \".join(missing))\n",
    "\n",
    "    # Function to load data from a tab-separated file\n",
    "    def load_results(path):\n",
    "        data = np.loadtxt(path, comments='#', delimiter='\\t')\n",
    "        # Assuming columns are: tau, p_amp, p_phase, ler\n",
    "        return data[:, 0], data[:, 3]\n",
    "\n",
    "    # Load data\n",
    "    tau_s, stim_ler_s = load_results(stim_results_path)\n",
    "    tau_c, cpp_ler_c = load_results(cpp_results_path)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(tau_s / T1, stim_ler_s, 'o-', label='Stim LER (BP+OSD) [loaded]')\n",
    "    plt.plot(tau_c / T1, cpp_ler_c, 's--', label='C++ LER (BP+OSD) [loaded]')\n",
    "    \n",
    "    plt.xlabel(r\"$\\tau / T1$ Ratio\")\n",
    "    plt.ylabel(\"Logical Error Rate (LER)\")\n",
    "    plt.title(f\"Loaded LER for BB Code (d={distance}), Shots={SHOTS}\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed to load and plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
