{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3a69b1",
   "metadata": {},
   "source": [
    "# Demo. Decoder Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ca904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import pymatching\n",
    "import sys\n",
    "sys.path.append(\"../QEC-Codes\")  # Adjust the path to import local modules\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QASM export setup (similar to surface_code_ler)\n",
    "import os, sys, importlib\n",
    "qasm_dir = \"./bb_code_qasm\"\n",
    "os.makedirs(qasm_dir, exist_ok=True)\n",
    "# Make sure we can import the conversion utilities\n",
    "sys.path.insert(0, os.path.abspath(\"../../../src\"))\n",
    "import noise_util as ns\n",
    "importlib.reload(ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ad4e4",
   "metadata": {},
   "source": [
    "This demo introduces the basics of decoders, focusing on pymatching and BP+OSD.  \n",
    "\n",
    "**What does decoder do?**  \n",
    "The input is the error information/syndromes/detection events, along with the detector error model that assigns probability/weights to each error mechanism. For each sample, the decoder will return a vector that gives the predictions for the logical errors that have happened (for surface code it's just one value because there is only one logical operator, for general codes it should a vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc864f9",
   "metadata": {},
   "source": [
    "### 1. Pymatching for repetition codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad0a82",
   "metadata": {},
   "source": [
    "### Overall Analysis  \n",
    "**LER decreases with increasing code distance and decreasing physical error rate (PER).**  \n",
    "This behavior is consistent with theoretical expectations: as the code distance increases, more physical errors are required to cause a logical error. Similarly, reducing the physical error rate naturally reduces the probability of uncorrectable faults.\n",
    "\n",
    "<!-- (2) **The break-even PER appears to be ≈ 1, meaning the repetition code always outperforms a single bit.**  \n",
    "At first glance, this seems to contradict the classical result that repetition codes only outperform a single bit when \\( p < 0.5 \\) — since majority vote fails above this threshold. However, the classical result is based on **majority vote decoding**, whereas our experiment uses a **matching decoder** (e.g., `pymatching`), which finds the most likely error consistent with the observed syndrome, and can operate effectively even at high error rates. As a result, it can outperform majority vote and maintain logical error suppression for a much wider range of \\( p \\), even approaching 1.\n",
    "\n",
    "(3) **The error threshold appears to be >0.5, meaning that increasing the code distance can suppresses the LER even when the PER is large.**  \n",
    "In standard fault-tolerance theory, a threshold exists below which increasing the code distance improves logical fidelity, and above which larger codes perform worse. Here, because we are using the powerful **matching decoder** on this simple repetition code, the threshold become very large (>0.5). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b79d4",
   "metadata": {},
   "source": [
    "### Analysis of LER Scaling\n",
    "\n",
    "In principle, a QEC code of distance $d$ can correct up to $t = \\lfloor \\frac{d-1}{2} \\rfloor$ errors. In the **ideal** case where all these errors are corrected, the leading-order contribution to the LER should be $p^{t+1}$, where $t + 1 = \\lceil \\frac{d+1}{2} \\rceil$ is the weight of uncorrectable errors. In this case, a log-log plot of LER vs $p$ should produce a straight line with slope $t + 1$.\n",
    "\n",
    "In realistic scenarios, however, decoding is imperfect: some correctable errors of weight ≤ $t$ may still lead to logical failure due to decoder suboptimality. As a result, the effective scaling exponent becomes **less than** $t + 1$.\n",
    "\n",
    "Therefore, by fitting the log-log curve $\\log(\\text{LER})$ vs $ \\log(p) $, we can estimate the effective suppression exponent. The **closer the slope is to t+1**, the more effective the decoder is at approaching the ideal case. Conversely, the difference between the slope and the ideal case quantifies suboptimal correction performance under the given noise model and decoding strategy. We can see that when d increases, the leading degrees become closer to t than t+1 and haves the tendency to drop even below t, indicating the fact that it becomes more and more difficult to correct all the errors up to weight t.  \n",
    "\n",
    "The equation $$slope = (d_{eff}+1)/2 $$can give a metric called the \"effective distance $d_{eff}$\", which should be strictly smaller than the true distance $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c63fb",
   "metadata": {},
   "source": [
    "Next, we verify the \"exponential suppression\" of LER in code distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinter\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7531f8",
   "metadata": {},
   "source": [
    "This time we try to add the 2Q gate error and measurement error as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bc77c",
   "metadata": {},
   "source": [
    "(1) We kind of see a \"threshold behavior\": the LER only suppresses as distance increases when PER is below 10.8\\%. See where the d = 7 and d = 9 line intersect.  \n",
    "(2) We also see a \"break even\" behavior: the LER is belowe PER when p < 10\\%, where encoding into repetition code improves the error resilience compared to a bare qubit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938674e",
   "metadata": {},
   "source": [
    "### 2. Pymatching for Surface Codes  \n",
    "We directly use Sinter to streamline the sampling. This time we include the BPOSD decoder as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bposdd import BPOSD\n",
    "import BBcode\n",
    "# from stimbposdd import SinterDecoder_BPOSD, sinter_decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Compile the C++ code once before the loop\n",
    "print(\"Compiling C++ simulator (MPI)...\")\n",
    "# Adjust the path to your C++ file as needed\n",
    "cpp_file_path = './bb_code_sim.cpp'\n",
    "executable_path = './bb_code_sim'\n",
    "\n",
    "compile_command = [\n",
    "    \"mpicxx\",  # Use MPI compiler wrapper\n",
    "    \"-std=c++17\",\n",
    "    \"-O3\",\n",
    "    \"-I../../../../../\", # Include for NWQ-Sim headers\n",
    "    \"-DMPI_ENABLED\",\n",
    "    \"-o\",\n",
    "    executable_path,\n",
    "    cpp_file_path\n",
    "]\n",
    "try:\n",
    "    subprocess.run(compile_command, check=True, capture_output=True, text=True)\n",
    "    print(\"Compilation successful.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Compilation failed.\")\n",
    "    print(\"--- stdout ---\")\n",
    "    print(e.stdout)\n",
    "    print(\"--- stderr ---\")\n",
    "    print(e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "circuit = \"bicycle_bivariate_144_12_12_memory_Z\"\n",
    "distance = 12 \n",
    "rounds = 12\n",
    "SHOTS = 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ff588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "tasks = []\n",
    "T1 = 10 ** -4\n",
    "T2 = 10 ** -4\n",
    "tau = np.array([8*10**-7, 10**-6, 2*10**-6, 3*10**-6, 4*10**-6, 6*10**-6])\n",
    "lam = 1/T2 - 1/(2*T1)\n",
    "p_amp = 1 - np.exp(-tau/T1)\n",
    "p_phase = 1 - np.exp(-lam*tau)\n",
    "p_list = (p_amp, p_phase)\n",
    "base_error = 0.000\n",
    "\n",
    "bb_code = BBcode.BBcode(\n",
    "    n=144, k=12, d=12, m=6, l=12,\n",
    "    A=[[3, 0], [0, 1], [0, 2]],\n",
    "    B=[[0, 3], [1, 0], [2, 0]],\n",
    "    shift=[0, 0],\n",
    "    f=[[0, 0], [1, 0], [2, 0], [3, 0], [6, 0], [7, 0], [8, 0], [9, 0], [1, 3], [5, 3], [7, 3], [11, 3]],\n",
    "    g=[[1, 0], [2, 1], [0, 2], [1, 2], [2, 3], [0, 4]],\n",
    "    h=[[0, 0], [0, 1], [1, 1], [0, 2], [0, 3], [1, 3]],\n",
    "    alpha=[[0, 0], [0, 1], [2, 1], [2, 5], [3, 2], [4, 0]],\n",
    "    beta=[[0, 1], [0, 5], [1, 1], [0, 0], [4, 0], [5, 2]],\n",
    ")\n",
    "print(p_amp)\n",
    "print(p_phase)\n",
    "i=0\n",
    "for p_amp, p_phase in zip(p_amp, p_phase):\n",
    "    noise_profile = [0,0,0,0]\n",
    "    circuit = bb_code.build_full_BBcode_circuit(rounds=rounds, noise_profile=noise_profile, observable_type=\"Z\", code_capacity=True)\n",
    "\n",
    "    #Generate stim circuit\n",
    "    model = ns.ErrorModel(circuit)\n",
    "    model.setting_error('Identity', False, f'DEPOLARIZE1({base_error})')\n",
    "    model.setting_error('Single_qubit', False, f'DEPOLARIZE1({base_error})')\n",
    "    model.setting_error('Two_qubit', False, f'DEPOLARIZE2({base_error})')\n",
    "    model.setting_error('Measurement', True, f'PAULI_CHANNEL_1({p_amp/4}, {p_amp/4}, {p_amp/4 + p_phase/2})')\n",
    "    model.setting_error('Reset', True, f'PAULI_CHANNEL_1({p_amp/4}, {p_amp/4}, {p_amp/4 + p_phase/2})')\n",
    "    stim_circuit = model.generate_noisy_circuit()\n",
    "    tasks.append(sinter.Task(circuit=stim_circuit, json_metadata={'d': distance, \"trial\":i}))\n",
    "\n",
    "    #Generate stabsim circuit\n",
    "    model.setting_error('Measurement', True, f'AMPLITUDE_DAMP({p_phase}, {p_amp})')\n",
    "    model.setting_error('Reset', True, f'AMPLITUDE_DAMP({p_phase}, {p_amp})')\n",
    "    stab_circuit = model.generate_noisy_circuit()\n",
    "    qasm_output = ns.stim_to_qasm_with_depolarize_noise(stab_circuit)\n",
    "    # Inject AMPLITUDE_DAMP around M/RESET in QASM using the model settings\n",
    "    qasm_output = ns.inject_amplitude_damp(qasm_output, model)\n",
    "    \n",
    "    try:\n",
    "        qasm_path = os.path.join(qasm_dir, f\"bb_code_d{distance}_p{i}.qasm\")\n",
    "        with open(qasm_path, \"w\") as f:\n",
    "            f.write(qasm_output)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to export QASM for p={p_amp}: {e}\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import bposd_mp\n",
    "import sys\n",
    "# Add path to MagicCross-main for GPU decoder utilities\n",
    "# sys.path.insert(0, os.path.abspath('./MagicCross-main/src'))\n",
    "import cudaq_qec as qec\n",
    "from beliefmatching import detector_error_model_to_check_matrices\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "\n",
    "def gpu_decode_worker(gpu_idx, det_chunk, obs_chunk, check_matrix, logicals_matrix, decoder_params, result_queue):\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_idx)\n",
    "    import numpy as np\n",
    "\n",
    "    try:\n",
    "        nvdec = qec.get_decoder('nv-qldpc-decoder', check_matrix, **decoder_params)\n",
    "        results = nvdec.decode_batch(det_chunk)\n",
    "        decoded = np.array([e.result for e in results])\n",
    "        \n",
    "        errors = 0\n",
    "        for i in range(decoded.shape[0]):\n",
    "            ans = (logicals_matrix @ decoded[i] + obs_chunk[i]) % 2\n",
    "            if ans.any():\n",
    "                errors += 1\n",
    "        result_queue.put(errors)\n",
    "    except Exception as e:\n",
    "        result_queue.put(f\"Error in GPU worker {gpu_idx}: {e}\")\n",
    "\n",
    "def gpu_decode_ler(dem, cpp_det_samples, cpp_obs_flips, gpu_num=4, process_per_gpu=1):\n",
    "    pcm = detector_error_model_to_check_matrices(dem, allow_undecomposed_hyperedges=True)\n",
    "    logicals_matrix = pcm.observables_matrix\n",
    "    check_matrix = np.array(pcm.check_matrix.todense(), dtype=np.uint8)\n",
    "\n",
    "    decoder_params = {\n",
    "        'error_rate_vec': pcm.priors,\n",
    "        'max_iterations': 1000,\n",
    "        'use_osd': True,\n",
    "        'osd_method': 3, # OSD-CS\n",
    "        'osd_order': 10,\n",
    "        'bp_batch_size': 1000,\n",
    "        'use_sparsity': True,\n",
    "    }\n",
    "\n",
    "    total_shots = len(cpp_det_samples)\n",
    "    if total_shots == 0:\n",
    "        return 0.0\n",
    "\n",
    "    num_decode_workers = gpu_num * process_per_gpu\n",
    "    chunk_size = (total_shots + num_decode_workers - 1) // num_decode_workers\n",
    "    \n",
    "    det_chunks = [cpp_det_samples[i:i + chunk_size] for i in range(0, total_shots, chunk_size)]\n",
    "    obs_chunks = [cpp_obs_flips[i:i + chunk_size] for i in range(0, total_shots, chunk_size)]\n",
    "\n",
    "    result_queue = mp.Queue()\n",
    "    processes = []\n",
    "\n",
    "    for i in range(len(det_chunks)):\n",
    "        gpu_idx = i % gpu_num\n",
    "        p = mp.Process(target=gpu_decode_worker, args=(\n",
    "            gpu_idx, det_chunks[i], obs_chunks[i], check_matrix, logicals_matrix, decoder_params, result_queue\n",
    "        ))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    total_errors = 0\n",
    "    while not result_queue.empty():\n",
    "        result = result_queue.get()\n",
    "        if isinstance(result, int):\n",
    "            total_errors += result\n",
    "        else:\n",
    "            print(result) # Print errors from workers\n",
    "\n",
    "    return float(total_errors) / float(total_shots)\n",
    "\n",
    "\n",
    "def run_cpp_experiment(tasks, shots):\n",
    "    cpp_lers = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        p = task.json_metadata.get('pM', 0)\n",
    "        d = task.json_metadata.get('d', 0)\n",
    "        print(f\"\\n--- Running C++ (MPI) for p = {i} ---\")\n",
    "\n",
    "        # Paths\n",
    "        p_tag = f\"{p:.0e}\".replace(\"+\", \"\")\n",
    "        qasm_file_path = os.path.join(qasm_dir, f\"bb_code_d{d}_p{i}.qasm\")\n",
    "        cpp_output_path = os.path.join(qasm_dir, f\"measurements_d{d}_p{i}.txt\")\n",
    "\n",
    "        # MPI execution\n",
    "        num_qubits = task.circuit.num_qubits\n",
    "        mpi_ranks = max(1, int(os.cpu_count() * 0.8))\n",
    "        iters = shots\n",
    "\n",
    "        env = os.environ.copy()\n",
    "        env.update({\n",
    "            \"OMP_NUM_THREADS\": \"1\",\n",
    "            \"OPENBLAS_NUM_THREADS\": \"1\",\n",
    "            \"MKL_NUM_THREADS\": \"1\",\n",
    "            \"VECLIB_MAXIMUM_THREADS\": \"1\",\n",
    "            \"NUMEXPR_NUM_THREADS\": \"1\",\n",
    "        })\n",
    "\n",
    "        run_command = [\n",
    "            \"mpirun\", \"-np\", str(mpi_ranks),\n",
    "            \"./bb_code_sim\", str(num_qubits), str(iters), qasm_file_path, cpp_output_path\n",
    "        ]\n",
    "\n",
    "        cpp_time = 0.0\n",
    "        try:\n",
    "            result = subprocess.run(run_command, check=True, capture_output=True, text=True, env=env)\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if \"Total C++ simulation time\" in line:\n",
    "                    try:\n",
    "                        cpp_time = float(line.split(':')[1].strip().replace('s', ''))\n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"C++ simulation failed to execute.\")\n",
    "            print(\"Return code:\", e.returncode)\n",
    "            print(\"--- stdout ---\")\n",
    "            print(e.stdout)\n",
    "            print(\"--- stderr ---\")\n",
    "            print(e.stderr)\n",
    "            cpp_lers.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # Post-process + GPU BPOSD decoding\n",
    "        cpp_ler = 0.0\n",
    "        try:\n",
    "            with open(cpp_output_path, \"r\") as f:\n",
    "                measurement_strings = [line for line in f.read().strip().split('\\n') if line]\n",
    "\n",
    "            if measurement_strings:\n",
    "                measurement_data = np.array(\n",
    "                    [list(map(int, line.split())) for line in measurement_strings],\n",
    "                    dtype=np.uint8\n",
    "                ).astype(bool)\n",
    "\n",
    "                m2d_converter = task.circuit.compile_m2d_converter()\n",
    "                cpp_det_samples, cpp_obs_flips = m2d_converter.convert(\n",
    "                    measurements=measurement_data,\n",
    "                    separate_observables=True\n",
    "                )\n",
    "\n",
    "                dem = task.circuit.detector_error_model(\n",
    "                    decompose_errors=True,\n",
    "                    ignore_decomposition_failures=True\n",
    "                )\n",
    "                \n",
    "                decode_start_time = time.perf_counter()\n",
    "                cpp_ler = gpu_decode_ler(dem, cpp_det_samples, cpp_obs_flips)\n",
    "                decode_time = time.perf_counter() - decode_start_time\n",
    "                print(f\"GPU Decoding Time: {decode_time:.4f}s\")\n",
    "\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"C++ output file not found at {cpp_output_path}. Skipping analysis.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during decoding: {e}\")\n",
    "\n",
    "\n",
    "        cpp_lers.append(cpp_ler)\n",
    "        print(f\"C++ LER: {cpp_ler}, Sim Time: {cpp_time}s\")\n",
    "    return cpp_lers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658dfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stim_experiment(tasks, shots):\n",
    "    stim_lers = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        print(f\"\\n--- Running Stim for p = {i} ---\")\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Get detector error model from the circuit\n",
    "        dem = task.circuit.detector_error_model(\n",
    "            decompose_errors=True,\n",
    "            ignore_decomposition_failures=True\n",
    "        )\n",
    "\n",
    "        # Sample detection events and logical observables from stim\n",
    "        sampler = task.circuit.compile_detector_sampler()\n",
    "        stim_det_samples, stim_obs_flips = sampler.sample(\n",
    "            shots, separate_observables=True, bit_packed=False\n",
    "        )\n",
    "        \n",
    "        sim_time = time.perf_counter() - start_time\n",
    "        print(f\"Stim Sampling Time: {sim_time:.4f}s\")\n",
    "\n",
    "        # Decode using the GPU decoder\n",
    "        decode_start_time = time.perf_counter()\n",
    "        stim_ler = gpu_decode_ler(dem, stim_det_samples, stim_obs_flips)\n",
    "        decode_time = time.perf_counter() - decode_start_time\n",
    "        \n",
    "        stim_lers.append(stim_ler)\n",
    "        print(f\"GPU Decoding Time: {decode_time:.4f}s\")\n",
    "        print(f\"Stim LER: {stim_ler}\")\n",
    "\n",
    "    return stim_lers\n",
    "\n",
    "# --- Run Stim-only experiment ---\n",
    "stim_logical_error_rates = run_stim_experiment(tasks, SHOTS)\n",
    "print(\"\\nStim complete.\")\n",
    "print(\"Stim LERs:\", stim_logical_error_rates)\n",
    "\n",
    "try:\n",
    "    results_dir = \"./results\"\n",
    "    p_amp_arr = 1 - np.exp(-tau / T1)\n",
    "    lam = 1 / T2 - 1 / (2 * T1)\n",
    "    p_phase_arr = 1 - np.exp(-lam * tau)\n",
    "    stim_results_path = os.path.join(results_dir, f\"stim_bposd_gpu_results_d{distance}_shots{SHOTS}.txt\")\n",
    "    with open(stim_results_path, \"w\") as f:\n",
    "        f.write(\"# tau\\tp_amp\\tp_phase\\tstim_ler\\n\")\n",
    "        for ta, pa, pp, ler in zip(tau, p_amp_arr, p_phase_arr, stim_logical_error_rates):\n",
    "            f.write(f\"{ta}\\t{pa}\\t{pp}\\t{ler}\\n\")\n",
    "    print(f\"Saved Stim (BP+OSD-GPU) results to {stim_results_path}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save Stim results:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d936d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Run C++-only experiment ---\n",
    "# reuse SHOTS from previous cell\n",
    "cpp_logical_error_rates = run_cpp_experiment(tasks, SHOTS)\n",
    "print(\"\\nC++ complete.\")\n",
    "print(\"C++ LERs:\", cpp_logical_error_rates)\n",
    "# ...existing code...\n",
    "\n",
    "try:\n",
    "    results_dir = \"./results\"\n",
    "    p_amp_arr = 1 - np.exp(-tau / T1)\n",
    "    lam = 1 / T2 - 1 / (2 * T1)\n",
    "    p_phase_arr = 1 - np.exp(-lam * tau)\n",
    "    cpp_results_path = os.path.join(results_dir, f\"cpp_bposd_gpu_results_d{distance}_shots{SHOTS}.txt\")\n",
    "    with open(cpp_results_path, \"w\") as f:\n",
    "        f.write(\"# tau\\tp_amp\\tp_phase\\tcpp_ler\\n\")\n",
    "        for ta, pa, pp, ler in zip(tau, p_amp_arr, p_phase_arr, cpp_logical_error_rates):\n",
    "            f.write(f\"{ta}\\t{pa}\\t{pp}\\t{ler}\\n\")\n",
    "    print(f\"Saved C++ (BP+OSD) results to {cpp_results_path}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save C++ results:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, importlib\n",
    "qasm_dir = \"./bb_code_qasm\"\n",
    "os.makedirs(qasm_dir, exist_ok=True)\n",
    "\n",
    "# New: directory for saved results\n",
    "results_dir = \"./results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Make sure we can import the conversion utilities\n",
    "sys.path.insert(0, os.path.abspath(\"../../../src\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Results ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(tau/T1, stim_logical_error_rates, 'o-', label='Stim LER (BP+OSD)')\n",
    "plt.plot(tau/T1, cpp_logical_error_rates, 's--', label='C++ LER (BP+OSD)')\n",
    "plt.xlabel(\"Physical Error Rate (p)\")\n",
    "plt.ylabel(\"Logical Error Rate (LER)\")\n",
    "plt.title(f\"LER vs. Physical Error Rate for BB Code (d={distance}) Shots= {SHOTS}\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6bfc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Reload and plot previously saved results ---\n",
    "\n",
    "# Ensure these parameters match the saved files you want to load\n",
    "# SHOTS = 50000000\n",
    "# distance = 12\n",
    "# T1 = 10**-4\n",
    "# T2 = 10**-4\n",
    "\n",
    "try:\n",
    "    results_dir = \"./results\"\n",
    "    stim_results_path = Path(results_dir) / f\"stim_bposd_results_d{distance}_shots{SHOTS}.txt\"\n",
    "    cpp_results_path = Path(results_dir) / f\"cpp_bposd_results_d{distance}_shots{SHOTS}.txt\"\n",
    "\n",
    "    # Check if files exist\n",
    "    if not stim_results_path.exists() or not cpp_results_path.exists():\n",
    "        missing = []\n",
    "        if not stim_results_path.exists(): missing.append(str(stim_results_path))\n",
    "        if not cpp_results_path.exists(): missing.append(str(cpp_results_path))\n",
    "        raise FileNotFoundError(\"Missing results files: \" + \", \".join(missing))\n",
    "\n",
    "    # Function to load data from a tab-separated file\n",
    "    def load_results(path):\n",
    "        data = np.loadtxt(path, comments='#', delimiter='\\t')\n",
    "        # Assuming columns are: tau, p_amp, p_phase, ler\n",
    "        return data[:, 0], data[:, 3]\n",
    "\n",
    "    # Load data\n",
    "    tau_s, stim_ler_s = load_results(stim_results_path)\n",
    "    tau_c, cpp_ler_c = load_results(cpp_results_path)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(tau_s / T1, stim_ler_s, 'o-', label='Stim LER (BP+OSD) [loaded]')\n",
    "    plt.plot(tau_c / T1, cpp_ler_c, 's--', label='C++ LER (BP+OSD) [loaded]')\n",
    "    \n",
    "    plt.xlabel(r\"$\\tau / T1$ Ratio\")\n",
    "    plt.ylabel(\"Logical Error Rate (LER)\")\n",
    "    plt.title(f\"Loaded LER for BB Code (d={distance}), Shots={SHOTS}\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed to load and plot\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
